#!/usr/bin/env python3
"""
æµ‹è¯•è¯­è¨€åˆ†æåŠŸèƒ½
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend'))

from app.language_analyzer import LanguageAnalyzer
from app.project_analyzer import ProjectAnalyzer


async def test_language_analysis():
    """æµ‹è¯•è¯­è¨€åˆ†æåŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æµ‹è¯•è¯­è¨€åˆ†æåŠŸèƒ½...")
    
    # æµ‹è¯•è¯­è¨€åˆ†æå™¨
    analyzer = LanguageAnalyzer()
    
    # æµ‹è¯•å½“å‰é¡¹ç›®
    current_project = Path("/Users/mars/jobs/pq/edashboard")
    
    print(f"\nğŸ“ åˆ†æé¡¹ç›®: {current_project}")
    
    # åˆ†ææŠ€æœ¯æ ˆ
    tech_stack = analyzer.analyze_project_tech_stack(current_project)
    
    print("\nğŸ“Š æŠ€æœ¯æ ˆåˆ†æç»“æœ:")
    print("=" * 50)
    
    # ç¼–ç¨‹è¯­è¨€
    print("\nğŸ”¤ ç¼–ç¨‹è¯­è¨€:")
    for lang, count in tech_stack['languages'].items():
        print(f"  {lang}: {count} ä¸ªæ–‡ä»¶")
    
    # æ¡†æ¶
    print("\nâš™ï¸ æ¡†æ¶å’Œåº“:")
    for framework, count in tech_stack['frameworks'].items():
        print(f"  {framework}: {count} æ¬¡ä½¿ç”¨")
    
    # AIæŠ€æœ¯
    print("\nğŸ¤– AIæŠ€æœ¯:")
    ai_tech = tech_stack['ai_technologies']
    if ai_tech['models']:
        print("  AIæ¨¡å‹:")
        for model in ai_tech['models']:
            print(f"    - {model}")
    
    if ai_tech['libraries']:
        print("  AIåº“:")
        for library in ai_tech['libraries']:
            print(f"    - {library}")
    
    if ai_tech['runtimes']:
        print("  AIè¿è¡Œæ—¶:")
        for runtime in ai_tech['runtimes']:
            print(f"    - {runtime}")
    
    # æ‘˜è¦
    print("\nğŸ“‹ æŠ€æœ¯æ ˆæ‘˜è¦:")
    summary = tech_stack['summary']
    print(f"  ä¸»è¦è¯­è¨€: {summary.get('primary_language', 'Unknown')}")
    print(f"  è¯­è¨€ç§ç±»: {summary.get('language_count', 0)}")
    print(f"  æ¡†æ¶ç§ç±»: {summary.get('framework_count', 0)}")
    print(f"  ä¸»è¦æ¡†æ¶: {', '.join(summary.get('main_frameworks', []))}")
    print(f"  ä½¿ç”¨AI: {'æ˜¯' if summary.get('has_ai', False) else 'å¦'}")
    
    if summary.get('has_ai'):
        print(f"  AIæ¨¡å‹: {', '.join(summary.get('ai_models', []))}")
        print(f"  AIåº“: {', '.join(summary.get('ai_libraries', []))}")


async def test_project_analyzer():
    """æµ‹è¯•é¡¹ç›®åˆ†æå™¨"""
    print("\nğŸ” å¼€å§‹æµ‹è¯•é¡¹ç›®åˆ†æå™¨...")
    
    analyzer = ProjectAnalyzer()
    
    # åˆ†ææ‰€æœ‰é¡¹ç›®
    print("æ­£åœ¨åˆ†ææ‰€æœ‰é¡¹ç›®...")
    projects = await analyzer.analyze_all_projects()
    
    print(f"\nğŸ“Š æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®")
    
    # ç»Ÿè®¡æŠ€æœ¯æ ˆ
    language_stats = {}
    framework_stats = {}
    ai_project_count = 0
    
    for project_key, project_data in projects.items():
        tech_stack = project_data.get('tech_stack', {})
        
        # ç»Ÿè®¡è¯­è¨€
        for lang, count in tech_stack.get('languages', {}).items():
            if lang not in language_stats:
                language_stats[lang] = {'count': 0, 'projects': []}
            language_stats[lang]['count'] += count
            if project_key not in language_stats[lang]['projects']:
                language_stats[lang]['projects'].append(project_key)
        
        # ç»Ÿè®¡æ¡†æ¶
        for framework, count in tech_stack.get('frameworks', {}).items():
            if framework not in framework_stats:
                framework_stats[framework] = {'count': 0, 'projects': []}
            framework_stats[framework]['count'] += count
            if project_key not in framework_stats[framework]['projects']:
                framework_stats[framework]['projects'].append(project_key)
        
        # ç»Ÿè®¡AIé¡¹ç›®
        if tech_stack.get('summary', {}).get('has_ai', False):
            ai_project_count += 1
    
    print(f"\nğŸ”¤ ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡ (æŒ‰é¡¹ç›®æ•°é‡æ’åº):")
    sorted_languages = sorted(
        language_stats.items(), 
        key=lambda x: len(x[1]['projects']), 
        reverse=True
    )
    for lang, stats in sorted_languages[:10]:
        print(f"  {lang}: {len(stats['projects'])} ä¸ªé¡¹ç›®, {stats['count']} ä¸ªæ–‡ä»¶")
    
    print(f"\nâš™ï¸ æ¡†æ¶ç»Ÿè®¡ (æŒ‰é¡¹ç›®æ•°é‡æ’åº):")
    sorted_frameworks = sorted(
        framework_stats.items(), 
        key=lambda x: len(x[1]['projects']), 
        reverse=True
    )
    for framework, stats in sorted_frameworks[:10]:
        print(f"  {framework}: {len(stats['projects'])} ä¸ªé¡¹ç›®, {stats['count']} æ¬¡ä½¿ç”¨")
    
    print(f"\nğŸ¤– AIé¡¹ç›®ç»Ÿè®¡:")
    print(f"  ä½¿ç”¨AIæŠ€æœ¯çš„é¡¹ç›®: {ai_project_count}")
    print(f"  AIé¡¹ç›®å æ¯”: {(ai_project_count / len(projects) * 100):.1f}%")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è¯­è¨€å’Œæ¡†æ¶åˆ†ææµ‹è¯•")
    print("=" * 60)
    
    try:
        await test_language_analysis()
        await test_project_analyzer()
        
        print("\nâœ… æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 