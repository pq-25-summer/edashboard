#!/usr/bin/env python3
"""
ä¿å­˜æŠ€æœ¯æ ˆæ•°æ®åˆ°æ•°æ®åº“
"""

import asyncio
import sys
import os
import json
from datetime import datetime

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend'))

from app.database import db, init_db
from app.language_analyzer import LanguageAnalyzer
from app.project_analyzer import ProjectAnalyzer


async def create_tech_stack_tables():
    """åˆ›å»ºæŠ€æœ¯æ ˆç›¸å…³çš„æ•°æ®åº“è¡¨"""
    async with db.get_db() as conn:
        # åˆ›å»ºé¡¹ç›®æŠ€æœ¯æ ˆè¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS project_tech_stacks (
                id SERIAL PRIMARY KEY,
                project_id INTEGER REFERENCES projects(id) UNIQUE,
                languages JSONB,
                frameworks JSONB,
                ai_models JSONB,
                ai_libraries JSONB,
                ai_runtimes JSONB,
                total_languages INTEGER DEFAULT 0,
                total_frameworks INTEGER DEFAULT 0,
                total_ai_models INTEGER DEFAULT 0,
                total_ai_libraries INTEGER DEFAULT 0,
                has_ai BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # åˆ›å»ºæŠ€æœ¯æ ˆç»Ÿè®¡è¡¨
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS tech_stack_statistics (
                id SERIAL PRIMARY KEY,
                language_summary JSONB,
                framework_summary JSONB,
                ai_summary JSONB,
                total_projects INTEGER DEFAULT 0,
                analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        await conn.commit()
        print("âœ… æŠ€æœ¯æ ˆè¡¨åˆ›å»ºå®Œæˆ")


async def save_project_tech_stacks():
    """ä¿å­˜é¡¹ç›®æŠ€æœ¯æ ˆæ•°æ®"""
    analyzer = ProjectAnalyzer()
    language_analyzer = LanguageAnalyzer()
    
    print("ğŸ” å¼€å§‹åˆ†æé¡¹ç›®æŠ€æœ¯æ ˆ...")
    
    # åˆ†ææ‰€æœ‰é¡¹ç›®
    results = await analyzer.analyze_all_projects()
    
    async with db.get_db() as conn:
        for project_key, project_data in results.items():
            try:
                # æŸ¥æ‰¾é¡¹ç›®ID
                async with conn.cursor() as cur:
                    # ä»project_keyæ„å»ºGitHub URLæ ¼å¼
                    if '/' in project_key:
                        owner, repo = project_key.split('/', 1)
                        github_url = f"https://github.com/{owner}/{repo}"
                        
                        await cur.execute(
                            "SELECT id FROM projects WHERE github_url = %s",
                            (github_url,)
                        )
                        project_result = await cur.fetchone()
                        
                        if not project_result:
                            print(f"âš ï¸  æœªæ‰¾åˆ°é¡¹ç›®: {project_key} (URL: {github_url})")
                            continue
                        
                        project_id = project_result["id"]
                        print(f"âœ… æ‰¾åˆ°é¡¹ç›®: {project_key} -> ID: {project_id}")
                    else:
                        print(f"âš ï¸  æ— æ•ˆçš„é¡¹ç›®é”®: {project_key}")
                        continue
                    
                    # åˆ†ææŠ€æœ¯æ ˆ
                    repo_path = project_data.get('path', '')
                    if repo_path and os.path.exists(repo_path):
                        try:
                            # æ£€æŸ¥é¡¹ç›®åˆ†æå™¨æ˜¯å¦å·²ç»åˆ†æäº†æŠ€æœ¯æ ˆ
                            if 'tech_stack' in project_data:
                                tech_stack = project_data['tech_stack']
                                print(f"ğŸ” ä½¿ç”¨é¡¹ç›®åˆ†æå™¨å·²æœ‰çš„æŠ€æœ¯æ ˆæ•°æ®")
                            else:
                                tech_stack = language_analyzer.analyze_project_tech_stack(repo_path)
                                print(f"ğŸ” é‡æ–°åˆ†æé¡¹ç›®æŠ€æœ¯æ ˆ")
                            
                            # æ‰“å°è°ƒè¯•ä¿¡æ¯
                            print(f"ğŸ” é¡¹ç›® {project_key} æŠ€æœ¯æ ˆåˆ†æç»“æœ:")
                            print(f"  - è¯­è¨€: {tech_stack['languages']}")
                            print(f"  - æ¡†æ¶: {tech_stack['frameworks']}")
                            print(f"  - AIæŠ€æœ¯: {tech_stack['ai_technologies']}")
                            
                            # ä¿å­˜æŠ€æœ¯æ ˆæ•°æ®
                            await cur.execute("""
                                INSERT INTO project_tech_stacks (
                                    project_id, languages, frameworks, ai_models, 
                                    ai_libraries, ai_runtimes, total_languages,
                                    total_frameworks, total_ai_models, total_ai_libraries,
                                    has_ai, updated_at
                                ) VALUES (
                                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW()
                                ) ON CONFLICT (project_id) DO UPDATE SET
                                    languages = EXCLUDED.languages,
                                    frameworks = EXCLUDED.frameworks,
                                    ai_models = EXCLUDED.ai_models,
                                    ai_libraries = EXCLUDED.ai_libraries,
                                    ai_runtimes = EXCLUDED.ai_runtimes,
                                    total_languages = EXCLUDED.total_languages,
                                    total_frameworks = EXCLUDED.total_frameworks,
                                    total_ai_models = EXCLUDED.total_ai_models,
                                    total_ai_libraries = EXCLUDED.total_ai_libraries,
                                    has_ai = EXCLUDED.has_ai,
                                    updated_at = NOW()
                            """, (
                                project_id,
                                json.dumps(tech_stack['languages']),
                                json.dumps(tech_stack['frameworks']),
                                json.dumps(tech_stack['ai_technologies']['models']),
                                json.dumps(tech_stack['ai_technologies']['libraries']),
                                json.dumps(tech_stack['ai_technologies']['runtimes']),
                                len(tech_stack['languages']),
                                len(tech_stack['frameworks']),
                                len(tech_stack['ai_technologies']['models']),
                                len(tech_stack['ai_technologies']['libraries']),
                                len(tech_stack['ai_technologies']['models']) > 0 or len(tech_stack['ai_technologies']['libraries']) > 0
                            ))
                            
                            print(f"âœ… å·²ä¿å­˜é¡¹ç›®æŠ€æœ¯æ ˆ: {project_key}")
                        except Exception as e:
                            print(f"âŒ åˆ†æé¡¹ç›®æŠ€æœ¯æ ˆå¤±è´¥ {project_key}: {e}")
                            import traceback
                            traceback.print_exc()
                    else:
                        print(f"âš ï¸  é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {repo_path}")
                    
            except Exception as e:
                print(f"âŒ ä¿å­˜é¡¹ç›®æŠ€æœ¯æ ˆå¤±è´¥ {project_key}: {e}")
        
        await conn.commit()


async def save_tech_stack_statistics():
    """ä¿å­˜æŠ€æœ¯æ ˆç»Ÿè®¡æ•°æ®"""
    print("ğŸ“Š ç”ŸæˆæŠ€æœ¯æ ˆç»Ÿè®¡æ•°æ®...")
    
    async with db.get_db() as conn:
        async with conn.cursor() as cur:
            # è·å–æ‰€æœ‰é¡¹ç›®æŠ€æœ¯æ ˆæ•°æ®
            await cur.execute("""
                SELECT languages, frameworks, ai_models, ai_libraries, has_ai
                FROM project_tech_stacks
            """)
            results = await cur.fetchall()
            
            # ç»Ÿè®¡è¯­è¨€ä½¿ç”¨æƒ…å†µ
            language_summary = {}
            framework_summary = {}
            ai_models_summary = {}
            ai_libraries_summary = {}
            projects_with_ai = 0
            
            for row in results:
                # ç»Ÿè®¡è¯­è¨€
                if row['languages']:
                    try:
                        languages = json.loads(row['languages']) if isinstance(row['languages'], str) else row['languages']
                        for lang, count in languages.items():
                            language_summary[lang] = language_summary.get(lang, 0) + 1
                    except:
                        pass
                
                # ç»Ÿè®¡æ¡†æ¶
                if row['frameworks']:
                    try:
                        frameworks = json.loads(row['frameworks']) if isinstance(row['frameworks'], str) else row['frameworks']
                        for framework, count in frameworks.items():
                            framework_summary[framework] = framework_summary.get(framework, 0) + 1
                    except:
                        pass
                
                # ç»Ÿè®¡AIæ¨¡å‹
                if row['ai_models']:
                    try:
                        ai_models = json.loads(row['ai_models']) if isinstance(row['ai_models'], str) else row['ai_models']
                        for model in ai_models:
                            ai_models_summary[model] = ai_models_summary.get(model, 0) + 1
                    except:
                        pass
                
                # ç»Ÿè®¡AIåº“
                if row['ai_libraries']:
                    try:
                        ai_libraries = json.loads(row['ai_libraries']) if isinstance(row['ai_libraries'], str) else row['ai_libraries']
                        for library in ai_libraries:
                            ai_libraries_summary[library] = ai_libraries_summary.get(library, 0) + 1
                    except:
                        pass
                
                # ç»Ÿè®¡AIé¡¹ç›®
                if row['has_ai']:
                    projects_with_ai += 1
            
            # ä¿å­˜ç»Ÿè®¡æ•°æ®
            await cur.execute("""
                INSERT INTO tech_stack_statistics (
                    language_summary, framework_summary, ai_summary, total_projects, analysis_time
                ) VALUES (
                    %s, %s, %s, %s, NOW()
                )
            """, (
                json.dumps(language_summary),
                json.dumps(framework_summary),
                json.dumps({
                    'ai_models': ai_models_summary,
                    'ai_libraries': ai_libraries_summary,
                    'projects_with_ai': projects_with_ai
                }),
                len(results)
            ))
            
            await conn.commit()
            
            print(f"âœ… æŠ€æœ¯æ ˆç»Ÿè®¡å®Œæˆ:")
            print(f"   - æ€»é¡¹ç›®æ•°: {len(results)}")
            print(f"   - è¯­è¨€ç§ç±»: {len(language_summary)}")
            print(f"   - æ¡†æ¶ç§ç±»: {len(framework_summary)}")
            print(f"   - AIé¡¹ç›®æ•°: {projects_with_ai}")
            print(f"   - AIæ¨¡å‹ç§ç±»: {len(ai_models_summary)}")
            print(f"   - AIåº“ç§ç±»: {len(ai_libraries_summary)}")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ’¾ æŠ€æœ¯æ ˆæ•°æ®ä¿å­˜ä»»åŠ¡")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db()
        
        # åˆ›å»ºæŠ€æœ¯æ ˆè¡¨
        await create_tech_stack_tables()
        
        # ä¿å­˜é¡¹ç›®æŠ€æœ¯æ ˆ
        await save_project_tech_stacks()
        
        # ä¿å­˜ç»Ÿè®¡æ•°æ®
        await save_tech_stack_statistics()
        
        print("\nğŸ‰ æŠ€æœ¯æ ˆæ•°æ®ä¿å­˜å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æŠ€æœ¯æ ˆæ•°æ®ä¿å­˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 